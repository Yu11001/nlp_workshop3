{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\24746\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\24746\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\24746\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv('data/spam.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# drop extra column\n",
    "data = data.dropna(how=\"any\", axis=1)\n",
    "data.columns = ['label', 'text']\n",
    "\n",
    "data = data.dropna(how=\"any\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda s: s.lower()).str.strip()\n",
    "data['text'] = data['text'].apply(lambda s: s.translate(str.maketrans(string.whitespace, ' '*len(string.whitespace),'')))\n",
    "data['text'] = data['text'].drop_duplicates()\n",
    "# replace non alphabeths with spaces, and collapse spaces\n",
    "data['text'] = data['text'].replace(r'[^A-Za-z\\d]', ' ', regex=True)\n",
    "data['text'] = data['text'].replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  length\n",
       "0   ham  go until jurong point crazy available only in ...      20\n",
       "1   ham                           ok lar joking wif u oni        6\n",
       "2  spam  free entry in 2 a wkly comp to win fa cup fina...      32\n",
       "3   ham       u dun say so early hor u c already then say       11\n",
       "4   ham  nah i don t think he goes to usf he lives arou...      13"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# message length\n",
    "data['length'] = data['text'].astype(str).apply(lambda x: len(x.split(' '))-1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>sentence</th>\n",
       "      <th>words</th>\n",
       "      <th>words_cleaned</th>\n",
       "      <th>stemmed_words</th>\n",
       "      <th>lemmatized_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>20</td>\n",
       "      <td>[go until jurong point crazy available only in...</td>\n",
       "      <td>[[go, until, jurong, point, crazy, available, ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, until, jurong, point, crazi, avail, onli,...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>6</td>\n",
       "      <td>[ok lar joking wif u oni]</td>\n",
       "      <td>[[ok, lar, joking, wif, u, oni]]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>32</td>\n",
       "      <td>[free entry in 2 a wkly comp to win fa cup fin...</td>\n",
       "      <td>[[free, entry, in, 2, a, wkly, comp, to, win, ...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>11</td>\n",
       "      <td>[u dun say so early hor u c already then say]</td>\n",
       "      <td>[[u, dun, say, so, early, hor, u, c, already, ...</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, so, earli, hor, u, c, alreadi, t...</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "      <td>13</td>\n",
       "      <td>[nah i don t think he goes to usf he lives aro...</td>\n",
       "      <td>[[nah, i, don, t, think, he, goes, to, usf, he...</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>[nah, i, don, t, think, he, goe, to, usf, he, ...</td>\n",
       "      <td>[nah, i, don, t, think, he, go, to, usf, he, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>32</td>\n",
       "      <td>[this is the 2nd time we have tried 2 contact ...</td>\n",
       "      <td>[[this, is, the, 2nd, time, we, have, tried, 2...</td>\n",
       "      <td>[this, is, the, 2nd, time, we, have, tried, 2,...</td>\n",
       "      <td>[thi, is, the, 2nd, time, we, have, tri, 2, co...</td>\n",
       "      <td>[this, is, the, 2nd, time, we, have, tried, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>will b going to esplanade fr home</td>\n",
       "      <td>7</td>\n",
       "      <td>[will b going to esplanade fr home]</td>\n",
       "      <td>[[will, b, going, to, esplanade, fr, home]]</td>\n",
       "      <td>[will, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>[will, b, go, to, esplanad, fr, home]</td>\n",
       "      <td>[will, b, going, to, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>pity was in mood for that so any other suggest...</td>\n",
       "      <td>10</td>\n",
       "      <td>[pity was in mood for that so any other sugges...</td>\n",
       "      <td>[[pity, was, in, mood, for, that, so, any, oth...</td>\n",
       "      <td>[pity, was, in, mood, for, that, so, any, othe...</td>\n",
       "      <td>[piti, wa, in, mood, for, that, so, ani, other...</td>\n",
       "      <td>[pity, wa, in, mood, for, that, so, any, other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>the guy did some bitching but i acted like i d...</td>\n",
       "      <td>26</td>\n",
       "      <td>[the guy did some bitching but i acted like i ...</td>\n",
       "      <td>[[the, guy, did, some, bitching, but, i, acted...</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "      <td>[the, guy, did, some, bitch, but, i, act, like...</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>rofl its true to its name</td>\n",
       "      <td>5</td>\n",
       "      <td>[rofl its true to its name]</td>\n",
       "      <td>[[rofl, its, true, to, its, name]]</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "      <td>[rofl, it, true, to, it, name]</td>\n",
       "      <td>[rofl, it, true, to, it, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  length  \\\n",
       "0      ham  go until jurong point crazy available only in ...      20   \n",
       "1      ham                           ok lar joking wif u oni        6   \n",
       "2     spam  free entry in 2 a wkly comp to win fa cup fina...      32   \n",
       "3      ham       u dun say so early hor u c already then say       11   \n",
       "4      ham  nah i don t think he goes to usf he lives arou...      13   \n",
       "...    ...                                                ...     ...   \n",
       "5567  spam  this is the 2nd time we have tried 2 contact u...      32   \n",
       "5568   ham                 will b going to esplanade fr home        7   \n",
       "5569   ham  pity was in mood for that so any other suggest...      10   \n",
       "5570   ham  the guy did some bitching but i acted like i d...      26   \n",
       "5571   ham                          rofl its true to its name       5   \n",
       "\n",
       "                                               sentence  \\\n",
       "0     [go until jurong point crazy available only in...   \n",
       "1                             [ok lar joking wif u oni]   \n",
       "2     [free entry in 2 a wkly comp to win fa cup fin...   \n",
       "3         [u dun say so early hor u c already then say]   \n",
       "4     [nah i don t think he goes to usf he lives aro...   \n",
       "...                                                 ...   \n",
       "5567  [this is the 2nd time we have tried 2 contact ...   \n",
       "5568                [will b going to esplanade fr home]   \n",
       "5569  [pity was in mood for that so any other sugges...   \n",
       "5570  [the guy did some bitching but i acted like i ...   \n",
       "5571                        [rofl its true to its name]   \n",
       "\n",
       "                                                  words  \\\n",
       "0     [[go, until, jurong, point, crazy, available, ...   \n",
       "1                      [[ok, lar, joking, wif, u, oni]]   \n",
       "2     [[free, entry, in, 2, a, wkly, comp, to, win, ...   \n",
       "3     [[u, dun, say, so, early, hor, u, c, already, ...   \n",
       "4     [[nah, i, don, t, think, he, goes, to, usf, he...   \n",
       "...                                                 ...   \n",
       "5567  [[this, is, the, 2nd, time, we, have, tried, 2...   \n",
       "5568        [[will, b, going, to, esplanade, fr, home]]   \n",
       "5569  [[pity, was, in, mood, for, that, so, any, oth...   \n",
       "5570  [[the, guy, did, some, bitching, but, i, acted...   \n",
       "5571                 [[rofl, its, true, to, its, name]]   \n",
       "\n",
       "                                          words_cleaned  \\\n",
       "0     [go, until, jurong, point, crazy, available, o...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "3     [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4     [nah, i, don, t, think, he, goes, to, usf, he,...   \n",
       "...                                                 ...   \n",
       "5567  [this, is, the, 2nd, time, we, have, tried, 2,...   \n",
       "5568          [will, b, going, to, esplanade, fr, home]   \n",
       "5569  [pity, was, in, mood, for, that, so, any, othe...   \n",
       "5570  [the, guy, did, some, bitching, but, i, acted,...   \n",
       "5571                   [rofl, its, true, to, its, name]   \n",
       "\n",
       "                                          stemmed_words  \\\n",
       "0     [go, until, jurong, point, crazi, avail, onli,...   \n",
       "1                          [ok, lar, joke, wif, u, oni]   \n",
       "2     [free, entri, in, 2, a, wkli, comp, to, win, f...   \n",
       "3     [u, dun, say, so, earli, hor, u, c, alreadi, t...   \n",
       "4     [nah, i, don, t, think, he, goe, to, usf, he, ...   \n",
       "...                                                 ...   \n",
       "5567  [thi, is, the, 2nd, time, we, have, tri, 2, co...   \n",
       "5568              [will, b, go, to, esplanad, fr, home]   \n",
       "5569  [piti, wa, in, mood, for, that, so, ani, other...   \n",
       "5570  [the, guy, did, some, bitch, but, i, act, like...   \n",
       "5571                     [rofl, it, true, to, it, name]   \n",
       "\n",
       "                                       lemmatized_words  \n",
       "0     [go, until, jurong, point, crazy, available, o...  \n",
       "1                        [ok, lar, joking, wif, u, oni]  \n",
       "2     [free, entry, in, 2, a, wkly, comp, to, win, f...  \n",
       "3     [u, dun, say, so, early, hor, u, c, already, t...  \n",
       "4     [nah, i, don, t, think, he, go, to, usf, he, l...  \n",
       "...                                                 ...  \n",
       "5567  [this, is, the, 2nd, time, we, have, tried, 2,...  \n",
       "5568          [will, b, going, to, esplanade, fr, home]  \n",
       "5569  [pity, wa, in, mood, for, that, so, any, other...  \n",
       "5570  [the, guy, did, some, bitching, but, i, acted,...  \n",
       "5571                     [rofl, it, true, to, it, name]  \n",
       "\n",
       "[5572 rows x 8 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization\n",
    "data['sentence'] = data['text'].astype(str).map(sent_tokenize)\n",
    "\n",
    "data['words'] = data['sentence'].apply(lambda sentences: [word_tokenize(sentence) for sentence in sentences])\n",
    "data['words_cleaned'] = data['words'].apply(lambda word_lists: [word for sublist in word_lists for word in sublist if word.isalnum()])\n",
    "\n",
    "# remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words_cleaned = data['words_cleaned']\n",
    "\n",
    "new_filtered_words = [word for word in words_cleaned if word not in stopwords.words('english')]\n",
    "\n",
    "# emoticons, symbols\n",
    "emoticon_pattern = re.compile(\"[\"  \n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    u\"\\U00002500-\\U00002BEF\"  # Chinese characters\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "\n",
    "data = data.replace(emoticon_pattern, '', regex=True)\n",
    "\n",
    "# remove extra columns which save tokenized sent and word\n",
    "# data = data.drop(['words','sentence'], axis=1) \n",
    "\n",
    "# stemming\n",
    "ps = PorterStemmer()\n",
    "data['stemmed_words'] = data['words_cleaned'].map(lambda words: [ps.stem(word) for word in words])\n",
    "\n",
    "# lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['lemmatized_words'] = data['words_cleaned'].map(lambda words: [lemmatizer.lemmatize(word) for word in words])\n",
    "\n",
    "data.to_csv('data/results.csv', index=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>words_cleaned</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>20</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>Todays Voda numbers ending 1225 are selected t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>6</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>If you have a match please call 087123002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>32</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>todays voda numbers ending selected receive aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>11</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "      <td>13</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>32</td>\n",
       "      <td>[this, is, the, 2nd, time, we, have, tried, 2,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>will b going to esplanade fr home</td>\n",
       "      <td>7</td>\n",
       "      <td>[will, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>pity was in mood for that so any other suggest...</td>\n",
       "      <td>10</td>\n",
       "      <td>[pity, was, in, mood, for, that, so, any, othe...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>the guy did some bitching but i acted like i d...</td>\n",
       "      <td>26</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>rofl its true to its name</td>\n",
       "      <td>5</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  length  \\\n",
       "0      ham  go until jurong point crazy available only in ...      20   \n",
       "1      ham                           ok lar joking wif u oni        6   \n",
       "2     spam  free entry in 2 a wkly comp to win fa cup fina...      32   \n",
       "3      ham       u dun say so early hor u c already then say       11   \n",
       "4      ham  nah i don t think he goes to usf he lives arou...      13   \n",
       "...    ...                                                ...     ...   \n",
       "5567  spam  this is the 2nd time we have tried 2 contact u...      32   \n",
       "5568   ham                 will b going to esplanade fr home        7   \n",
       "5569   ham  pity was in mood for that so any other suggest...      10   \n",
       "5570   ham  the guy did some bitching but i acted like i d...      26   \n",
       "5571   ham                          rofl its true to its name       5   \n",
       "\n",
       "                                          words_cleaned  \\\n",
       "0     [go, until, jurong, point, crazy, available, o...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "3     [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4     [nah, i, don, t, think, he, goes, to, usf, he,...   \n",
       "...                                                 ...   \n",
       "5567  [this, is, the, 2nd, time, we, have, tried, 2,...   \n",
       "5568          [will, b, going, to, esplanade, fr, home]   \n",
       "5569  [pity, was, in, mood, for, that, so, any, othe...   \n",
       "5570  [the, guy, did, some, bitching, but, i, acted,...   \n",
       "5571                   [rofl, its, true, to, its, name]   \n",
       "\n",
       "                                                  text2  \n",
       "0     Todays Voda numbers ending 1225 are selected t...  \n",
       "1          If you have a match please call 087123002...  \n",
       "2     todays voda numbers ending selected receive aw...  \n",
       "3                                                   NaN  \n",
       "4                                                   NaN  \n",
       "...                                                 ...  \n",
       "5567                                                NaN  \n",
       "5568                                                NaN  \n",
       "5569                                                NaN  \n",
       "5570                                                NaN  \n",
       "5571                                                NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text2'] = pd.Series([\n",
    "    'Todays Voda numbers ending 1225 are selected to receive a å£50award. \\'',\n",
    "    '     If you have a match please call 08712300220 quoting claim code 3100 standard rates app\")',\n",
    "    'todays voda numbers ending selected receive award match quoting claim code standard rates app'\n",
    "    ])\n",
    "\n",
    "# remove extra columns which save tokenized sent and word\n",
    "data = data.drop(['words','sentence','stemmed_words', 'lemmatized_words'], axis=1) \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1174, 3263, 1075, ..., 3418, 4063, 3558])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use labelEncoder method to convert class target\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit_transform(data['text'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['text'].astype(str))\n",
    "vectorizer.get_feature_names_out()\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00 in', '00 per', '00 sub', ..., 'zoom to', 'zouk with',\n",
       "       'zyada kisi'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "X2 = vectorizer2.fit_transform(data['text'].astype(str))\n",
    "vectorizer2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zed</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 8622 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  000pes  008704050406  0089  0121  01223585236  01223585334  \\\n",
       "0      0    0       0             0     0     0            0            0   \n",
       "1      0    0       0             0     0     0            0            0   \n",
       "2      0    0       0             0     0     0            0            0   \n",
       "3      0    0       0             0     0     0            0            0   \n",
       "4      0    0       0             0     0     0            0            0   \n",
       "...   ..  ...     ...           ...   ...   ...          ...          ...   \n",
       "5567   0    0       0             0     0     0            0            0   \n",
       "5568   0    0       0             0     0     0            0            0   \n",
       "5569   0    0       0             0     0     0            0            0   \n",
       "5570   0    0       0             0     0     0            0            0   \n",
       "5571   0    0       0             0     0     0            0            0   \n",
       "\n",
       "      0125698789  02  ...  zebra  zed  zeros  zhong  zindgi  zoe  zogtorius  \\\n",
       "0              0   0  ...      0    0      0      0       0    0          0   \n",
       "1              0   0  ...      0    0      0      0       0    0          0   \n",
       "2              0   0  ...      0    0      0      0       0    0          0   \n",
       "3              0   0  ...      0    0      0      0       0    0          0   \n",
       "4              0   0  ...      0    0      0      0       0    0          0   \n",
       "...          ...  ..  ...    ...  ...    ...    ...     ...  ...        ...   \n",
       "5567           0   0  ...      0    0      0      0       0    0          0   \n",
       "5568           0   0  ...      0    0      0      0       0    0          0   \n",
       "5569           0   0  ...      0    0      0      0       0    0          0   \n",
       "5570           0   0  ...      0    0      0      0       0    0          0   \n",
       "5571           0   0  ...      0    0      0      0       0    0          0   \n",
       "\n",
       "      zoom  zouk  zyada  \n",
       "0        0     0      0  \n",
       "1        0     0      0  \n",
       "2        0     0      0  \n",
       "3        0     0      0  \n",
       "4        0     0      0  \n",
       "...    ...   ...    ...  \n",
       "5567     0     0      0  \n",
       "5568     0     0      0  \n",
       "5569     0     0      0  \n",
       "5570     0     0      0  \n",
       "5571     0     0      0  \n",
       "\n",
       "[5572 rows x 8622 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 terms:\n",
      "you    2133\n",
      "to     2055\n",
      "the    1232\n",
      "and     929\n",
      "in      825\n",
      "dtype: int64\n",
      "\n",
      "Bottom 5 terms:\n",
      "young          1\n",
      "younger        1\n",
      "youphone       1\n",
      "02072069400    1\n",
      "0125698789     1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sorted_terms = df_bow.sum(axis=0).sort_values(ascending=False)\n",
    "print(\"\\nTop 5 terms:\")\n",
    "print(sorted_terms.head(5))\n",
    "\n",
    "print(\"\\nBottom 5 terms:\")\n",
    "print(sorted_terms.tail(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
